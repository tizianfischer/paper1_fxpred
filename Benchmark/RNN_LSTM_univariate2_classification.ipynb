{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "drawn-drinking",
   "metadata": {},
   "source": [
    "# A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unlimited-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# %% Loading Packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from collections import Counter\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_erIPython.notebook.kernel.execute('nb_name = \"' + IPython.notebook.notebook_name + '\"')ror\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.activations import tanh\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import MSE, MAE, MAPE\n",
    "from tensorflow.keras.metrics import Accuracy, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.losses import kullback_leibler_divergence, SparseCategoricalCrossentropy, KLDivergence\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import sys\n",
    "\n",
    "from tensorflow.python.ops.gen_batch_ops import batch\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "from tensorflow.python.ops.gen_math_ops import Tanh\n",
    "if platform.node() in ['msbq', 'msdai']:\n",
    "    os.chdir('/home/ms/github/fxpred')\n",
    "    # os.chdir('../.')\n",
    "    sys.path.append(os.path.join(os.getcwd(), 'Transformer'))\n",
    "# from utils import data_read_dict, data_read_concat, data_merge\n",
    "from utils import get_fx_and_metric_data_wo_weekend, mde\n",
    "from utils_NN_opt_learning_rate import opt_learn_rate_plot\n",
    "from benchmark_utils import actual_pred_plot, ts_train_test_normalize\n",
    "\n",
    "\n",
    "name = 'LSTM_univariate2_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "european-causing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ms/github/venv/fxpred3/lib/python3.8/site-packages/pandas/core/frame.py:4305: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "dtype = np.float32  # np.float64\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "# %% read in data and adapt\n",
    "df = get_fx_and_metric_data_wo_weekend(dtype=dtype)\n",
    "target = 'EURUSD BGNE Curncy Bid Close'\n",
    "target_column = list(df.columns).index(target)\n",
    "# df = df.loc[(df.iloc[:, :4] != 0).all(axis=1)]\n",
    "df_close = get_fx_and_metric_data_wo_weekend(dtype=dtype, pct_change=False)\n",
    "df = df.iloc[:, target_column : target_column + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "written-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# df = df.iloc[np.random.choice(list(range(df.shape[0])), size=df.shape[0], replace=False), :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "super-cutting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EURUSD BGNE Curncy Bid Close</th>\n",
       "      <th>strategy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-11-01 19:10:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 19:20:00</th>\n",
       "      <td>0.000275</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 19:30:00</th>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 19:40:00</th>\n",
       "      <td>0.000034</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01 19:50:00</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     EURUSD BGNE Curncy Bid Close  strategy\n",
       "Dates                                                      \n",
       "2020-11-01 19:10:00                      0.000000         1\n",
       "2020-11-01 19:20:00                      0.000275         2\n",
       "2020-11-01 19:30:00                     -0.000069         0\n",
       "2020-11-01 19:40:00                      0.000034         2\n",
       "2020-11-01 19:50:00                      0.000026         2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a list of our conditions #!!! \n",
    "conditions = [\n",
    "    (df[target] <= -0.00000001),\n",
    "    (df[target] > -0.00000001) & (df[target] <= 0.00000001),\n",
    "    (df[target] > 0.00000001)\n",
    "]\n",
    "\n",
    "# create a list of the values we want to assign for each condition #!!! \n",
    "values = ['sell', 'hold', 'buy']\n",
    "values = [0, 1, 2]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments #!!! \n",
    "df['strategy'] = np.select(conditions, values)\n",
    "df.strategy = df.strategy.astype(np.int32)\n",
    "\n",
    "# display updated DataFrame #!!! \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blessed-origin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['EURUSD BGNE Curncy Bid Close'].plot()\n",
    "plt.title('Return of closing price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "returning-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 128\n",
    "h = 1\n",
    "X_train, y_train, X_val, y_val , X_test, y_test, sc, sc_target, index_train, index_val, index_test, X_train_index, y_train_index = \\\n",
    "    ts_train_test_normalize(df, lag, h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "listed-mentor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23210,)\n",
      "(23081, 128, 2)\n",
      "(23081, 1)\n"
     ]
    }
   ],
   "source": [
    "print(index_train.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "former-peoples",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([sc.inverse_transform(X_train[i,:]) for i in range(X_train.shape[0])])\n",
    "b = np.concatenate([sc.inverse_transform(X_train[:,i])[:,np.newaxis] for i in range(128)], axis=1)\n",
    "a.shape == b.shape\n",
    "np.abs(a - b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "killing-increase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.621616654451048e-17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(a[:,-1] - df.loc[index_train].iloc[127:-2].values).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "textile-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert ((df.values[:X_train.shape[0]] - sc.inverse_transform(X_train)[:,0])**2).sum() < 1e-10\n",
    "# assert ((df.values[lag - 1:lag - 1 + X_train.shape[0]] - sc.inverse_transform(X_train)[:,-1])**2).sum() < 1e-10\n",
    "\n",
    "# assert ((df.iloc[-X_test.shape[0] - lag - h:][:-lag - h].values - sc.inverse_transform(X_test)[:,0])**2).sum() < 1e-11\n",
    "# assert index_test[0] == df.iloc[-X_test.shape[0] - lag - h:].index[0]\n",
    "# for i in range(lag):\n",
    "#     assert ((df.iloc[-X_test.shape[0] - lag - h:][i:-(lag + h -i)].values - sc.inverse_transform(X_test)[:,i])**2).sum() < 1e-10\n",
    "\n",
    "# assert (sc_target.inverse_transform(X_train[:, 0, 1]) == df.iloc[:X_train.shape[0], 1].values).all()\n",
    "# assert (sc_target.inverse_transform(X_train[:, -1, 1]) == df.iloc[lag - 1:lag - 1 + X_train.shape[0], 1].values).all()\n",
    "\n",
    "# assert (sc_target.inverse_transform(X_val[:, 0, 1]) == df.iloc[X_train.shape[0] + lag + 1: lag + 1 + X_train.shape[0] + X_val.shape[0], 1].values).all()\n",
    "# assert (sc_target.inverse_transform(X_val[:, -1, 1]) == df.iloc[X_train.shape[0] + lag + 1 + lag - 1: lag + 1 + lag - 1 + X_train.shape[0] + X_val.shape[0], 1].values).all()\n",
    "# # # assert (sc_target.inverse_transform(X_val[:, -1, 1]) == df.iloc[127:127 + X_train.shape[0], 1].values).all()\n",
    "# # print(sc.inverse_transform(X_test)[-10:, :4, 0])\n",
    "# # print(index_test[-4:])\n",
    "# # df.iloc[-10:, 0]\n",
    "# a = (sc.inverse_transform(X_train)[:, 0] == df.iloc[:23081])\n",
    "# np.sum((df.iloc[:23081].loc[np.invert(a).iloc[:, 0]] - sc.inverse_transform(X_train)[np.invert(a).iloc[:, 0], 0]) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "powered-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train#.astype(dtype)\n",
    "X_val = X_val#.astype(dtype)\n",
    "X_test = X_test#.astype(dtype)\n",
    "y_train = sc_target.inverse_transform(y_train)\n",
    "y_val = sc_target.inverse_transform(y_val)\n",
    "y_test = sc_target.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assigned-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model():\n",
    "    # The LSTM architecture\n",
    "    act_fct = 'tanh'\n",
    "    dr = 0.25\n",
    "    my_LSTM_model = Sequential()\n",
    "    my_LSTM_model.add(LSTM(units=128, activation=act_fct, return_sequences=True, dropout=dr))\n",
    "    my_LSTM_model.add(BatchNormalization())\n",
    "    my_LSTM_model.add(LSTM(units=128, activation=act_fct, return_sequences=True, dropout=dr))\n",
    "    my_LSTM_model.add(BatchNormalization())\n",
    "    my_LSTM_model.add(LSTM(units=64, activation=act_fct, return_sequences=True, dropout=dr))\n",
    "    my_LSTM_model.add(BatchNormalization())\n",
    "    my_LSTM_model.add(Flatten())\n",
    "    my_LSTM_model.add(Dropout(dr))\n",
    "    my_LSTM_model.add(Dense(units=128))\n",
    "    my_LSTM_model.add(Dense(units=3, activation='softmax'))\n",
    "    # my_LSTM_model.add(LSTM(units=1))\n",
    "    return my_LSTM_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "backed-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(my_model, X_test, sc=None):\n",
    "    LSTM_prediction = my_model.predict(X_test)\n",
    "    if sc is not None:\n",
    "        LSTM_prediction = sc.inverse_transform(LSTM_prediction)\n",
    "    return LSTM_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unable-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "def earlyStopping():\n",
    "    return tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        patience=10,\n",
    "        verbose=0,\n",
    "        mode=\"auto\",\n",
    "        baseline=None,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "if not os.path.exists('Benchmark/trained_models'):\n",
    "    os.mkdir('Benchmark/trained_models')\n",
    "model_checkpoints = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'Benchmark/trained_models/%s____{epoch:04}.hdf5'%name,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=False,\n",
    "    verbose=1\n",
    ")\n",
    "def learning_rate_scheduler(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.001\n",
    "    elif epoch < 10:\n",
    "        return 0.0005\n",
    "    elif epoch < 50:\n",
    "        return 0.0001\n",
    "    elif epoch < 100:\n",
    "        return 0.00001\n",
    "    else:\n",
    "        return 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "funded-vacation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "722/722 [==============================] - 16s 17ms/step - loss: 1.3886 - kullback_leibler_divergence: 4.7820 - accuracy: 0.4798 - val_loss: 0.8387 - val_kullback_leibler_divergence: 2.3819 - val_accuracy: 0.4766\n",
      "\n",
      "Epoch 00001: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0001.hdf5\n",
      "Epoch 2/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.8144 - kullback_leibler_divergence: 2.9410 - accuracy: 0.4922 - val_loss: 0.8352 - val_kullback_leibler_divergence: 2.3836 - val_accuracy: 0.4892\n",
      "\n",
      "Epoch 00002: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0002.hdf5\n",
      "Epoch 3/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.8119 - kullback_leibler_divergence: 2.9746 - accuracy: 0.4884 - val_loss: 0.8727 - val_kullback_leibler_divergence: 2.3731 - val_accuracy: 0.4780\n",
      "\n",
      "Epoch 00003: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0003.hdf5\n",
      "Epoch 4/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.8130 - kullback_leibler_divergence: 2.9992 - accuracy: 0.4978 - val_loss: 0.8087 - val_kullback_leibler_divergence: 3.0931 - val_accuracy: 0.4841\n",
      "\n",
      "Epoch 00004: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0004.hdf5\n",
      "Epoch 5/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.8084 - kullback_leibler_divergence: 3.0074 - accuracy: 0.4943 - val_loss: 0.8254 - val_kullback_leibler_divergence: 3.1484 - val_accuracy: 0.4913\n",
      "\n",
      "Epoch 00005: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0005.hdf5\n",
      "Epoch 6/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7885 - kullback_leibler_divergence: 3.0187 - accuracy: 0.4979 - val_loss: 0.7908 - val_kullback_leibler_divergence: 2.7075 - val_accuracy: 0.4867\n",
      "\n",
      "Epoch 00006: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0006.hdf5\n",
      "Epoch 7/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7851 - kullback_leibler_divergence: 3.0135 - accuracy: 0.5034 - val_loss: 0.7978 - val_kullback_leibler_divergence: 2.5754 - val_accuracy: 0.4827\n",
      "\n",
      "Epoch 00007: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0007.hdf5\n",
      "Epoch 8/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7832 - kullback_leibler_divergence: 3.0386 - accuracy: 0.5047 - val_loss: 0.7932 - val_kullback_leibler_divergence: 2.8457 - val_accuracy: 0.5040\n",
      "\n",
      "Epoch 00008: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0008.hdf5\n",
      "Epoch 9/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7824 - kullback_leibler_divergence: 3.0186 - accuracy: 0.5097 - val_loss: 0.7870 - val_kullback_leibler_divergence: 2.8929 - val_accuracy: 0.4971\n",
      "\n",
      "Epoch 00009: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0009.hdf5\n",
      "Epoch 10/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7798 - kullback_leibler_divergence: 3.0522 - accuracy: 0.5063 - val_loss: 0.7935 - val_kullback_leibler_divergence: 3.0187 - val_accuracy: 0.5123\n",
      "\n",
      "Epoch 00010: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0010.hdf5\n",
      "Epoch 11/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7668 - kullback_leibler_divergence: 3.0263 - accuracy: 0.5292 - val_loss: 0.7834 - val_kullback_leibler_divergence: 2.9699 - val_accuracy: 0.5007\n",
      "\n",
      "Epoch 00011: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0011.hdf5\n",
      "Epoch 12/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7615 - kullback_leibler_divergence: 3.0662 - accuracy: 0.5372 - val_loss: 0.7823 - val_kullback_leibler_divergence: 2.8531 - val_accuracy: 0.5087\n",
      "\n",
      "Epoch 00012: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0012.hdf5\n",
      "Epoch 13/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7589 - kullback_leibler_divergence: 3.1038 - accuracy: 0.5422 - val_loss: 0.7869 - val_kullback_leibler_divergence: 3.0112 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00013: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0013.hdf5\n",
      "Epoch 14/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7552 - kullback_leibler_divergence: 3.1229 - accuracy: 0.5421 - val_loss: 0.7913 - val_kullback_leibler_divergence: 2.9314 - val_accuracy: 0.5094\n",
      "\n",
      "Epoch 00014: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0014.hdf5\n",
      "Epoch 15/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.7550 - kullback_leibler_divergence: 3.1454 - accuracy: 0.5466 - val_loss: 0.7982 - val_kullback_leibler_divergence: 3.0848 - val_accuracy: 0.4968\n",
      "\n",
      "Epoch 00015: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0015.hdf5\n",
      "Epoch 16/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7519 - kullback_leibler_divergence: 3.1795 - accuracy: 0.5544 - val_loss: 0.7960 - val_kullback_leibler_divergence: 2.9572 - val_accuracy: 0.4989\n",
      "\n",
      "Epoch 00016: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0016.hdf5\n",
      "Epoch 17/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7501 - kullback_leibler_divergence: 3.2023 - accuracy: 0.5553 - val_loss: 0.7929 - val_kullback_leibler_divergence: 3.0129 - val_accuracy: 0.4805\n",
      "\n",
      "Epoch 00017: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0017.hdf5\n",
      "Epoch 18/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7496 - kullback_leibler_divergence: 3.1938 - accuracy: 0.5596 - val_loss: 0.7937 - val_kullback_leibler_divergence: 3.0460 - val_accuracy: 0.5040\n",
      "\n",
      "Epoch 00018: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0018.hdf5\n",
      "Epoch 19/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7498 - kullback_leibler_divergence: 3.2289 - accuracy: 0.5614 - val_loss: 0.8011 - val_kullback_leibler_divergence: 3.1149 - val_accuracy: 0.5011\n",
      "\n",
      "Epoch 00019: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0019.hdf5\n",
      "Epoch 20/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7462 - kullback_leibler_divergence: 3.2284 - accuracy: 0.5631 - val_loss: 0.7997 - val_kullback_leibler_divergence: 3.1292 - val_accuracy: 0.4877\n",
      "\n",
      "Epoch 00020: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0020.hdf5\n",
      "Epoch 21/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7432 - kullback_leibler_divergence: 3.2776 - accuracy: 0.5648 - val_loss: 0.8038 - val_kullback_leibler_divergence: 3.0232 - val_accuracy: 0.5004\n",
      "\n",
      "Epoch 00021: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0021.hdf5\n",
      "Epoch 22/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7434 - kullback_leibler_divergence: 3.2910 - accuracy: 0.5631 - val_loss: 0.8048 - val_kullback_leibler_divergence: 3.0379 - val_accuracy: 0.4863\n",
      "\n",
      "Epoch 00022: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0022.hdf5\n",
      "Epoch 23/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7420 - kullback_leibler_divergence: 3.2869 - accuracy: 0.5652 - val_loss: 0.8075 - val_kullback_leibler_divergence: 3.0437 - val_accuracy: 0.4888\n",
      "\n",
      "Epoch 00023: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0023.hdf5\n",
      "Epoch 24/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7398 - kullback_leibler_divergence: 3.3346 - accuracy: 0.5686 - val_loss: 0.8034 - val_kullback_leibler_divergence: 3.0049 - val_accuracy: 0.4874\n",
      "\n",
      "Epoch 00024: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0024.hdf5\n",
      "Epoch 25/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7386 - kullback_leibler_divergence: 3.3355 - accuracy: 0.5724 - val_loss: 0.8109 - val_kullback_leibler_divergence: 3.1255 - val_accuracy: 0.4899\n",
      "\n",
      "Epoch 00025: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0025.hdf5\n",
      "Epoch 26/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7364 - kullback_leibler_divergence: 3.3760 - accuracy: 0.5709 - val_loss: 0.8060 - val_kullback_leibler_divergence: 3.1729 - val_accuracy: 0.4996\n",
      "\n",
      "Epoch 00026: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0026.hdf5\n",
      "Epoch 27/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7353 - kullback_leibler_divergence: 3.4154 - accuracy: 0.5732 - val_loss: 0.8112 - val_kullback_leibler_divergence: 3.2048 - val_accuracy: 0.4953\n",
      "\n",
      "Epoch 00027: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0027.hdf5\n",
      "Epoch 28/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7317 - kullback_leibler_divergence: 3.4481 - accuracy: 0.5755 - val_loss: 0.8075 - val_kullback_leibler_divergence: 3.0190 - val_accuracy: 0.4899\n",
      "\n",
      "Epoch 00028: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0028.hdf5\n",
      "Epoch 29/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7332 - kullback_leibler_divergence: 3.4387 - accuracy: 0.5730 - val_loss: 0.8079 - val_kullback_leibler_divergence: 3.2306 - val_accuracy: 0.4935\n",
      "\n",
      "Epoch 00029: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0029.hdf5\n",
      "Epoch 30/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7308 - kullback_leibler_divergence: 3.4649 - accuracy: 0.5720 - val_loss: 0.8130 - val_kullback_leibler_divergence: 3.1826 - val_accuracy: 0.4924\n",
      "\n",
      "Epoch 00030: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0030.hdf5\n",
      "Epoch 31/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7285 - kullback_leibler_divergence: 3.5054 - accuracy: 0.5775 - val_loss: 0.8081 - val_kullback_leibler_divergence: 3.2079 - val_accuracy: 0.4939\n",
      "\n",
      "Epoch 00031: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0031.hdf5\n",
      "Epoch 32/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7275 - kullback_leibler_divergence: 3.4971 - accuracy: 0.5805 - val_loss: 0.8122 - val_kullback_leibler_divergence: 3.2096 - val_accuracy: 0.4953\n",
      "\n",
      "Epoch 00032: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0032.hdf5\n",
      "Epoch 33/100\n",
      "722/722 [==============================] - 11s 16ms/step - loss: 0.7275 - kullback_leibler_divergence: 3.4822 - accuracy: 0.5817 - val_loss: 0.8139 - val_kullback_leibler_divergence: 3.2194 - val_accuracy: 0.4895\n",
      "\n",
      "Epoch 00033: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0033.hdf5\n",
      "Epoch 34/100\n",
      "722/722 [==============================] - 11s 16ms/step - loss: 0.7222 - kullback_leibler_divergence: 3.5695 - accuracy: 0.5860 - val_loss: 0.8191 - val_kullback_leibler_divergence: 3.1808 - val_accuracy: 0.4993\n",
      "\n",
      "Epoch 00034: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0034.hdf5\n",
      "Epoch 35/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7241 - kullback_leibler_divergence: 3.5914 - accuracy: 0.5835 - val_loss: 0.8217 - val_kullback_leibler_divergence: 3.1422 - val_accuracy: 0.4975\n",
      "\n",
      "Epoch 00035: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0035.hdf5\n",
      "Epoch 36/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7229 - kullback_leibler_divergence: 3.5635 - accuracy: 0.5827 - val_loss: 0.8222 - val_kullback_leibler_divergence: 3.2205 - val_accuracy: 0.4971\n",
      "\n",
      "Epoch 00036: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0036.hdf5\n",
      "Epoch 37/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7225 - kullback_leibler_divergence: 3.5882 - accuracy: 0.5850 - val_loss: 0.8193 - val_kullback_leibler_divergence: 3.2152 - val_accuracy: 0.4960\n",
      "\n",
      "Epoch 00037: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0037.hdf5\n",
      "Epoch 38/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7197 - kullback_leibler_divergence: 3.5991 - accuracy: 0.5887 - val_loss: 0.8181 - val_kullback_leibler_divergence: 3.2202 - val_accuracy: 0.5004\n",
      "\n",
      "Epoch 00038: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0038.hdf5\n",
      "Epoch 39/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7150 - kullback_leibler_divergence: 3.6750 - accuracy: 0.5904 - val_loss: 0.8280 - val_kullback_leibler_divergence: 3.2041 - val_accuracy: 0.5022\n",
      "\n",
      "Epoch 00039: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0039.hdf5\n",
      "Epoch 40/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7172 - kullback_leibler_divergence: 3.6509 - accuracy: 0.5904 - val_loss: 0.8191 - val_kullback_leibler_divergence: 3.2841 - val_accuracy: 0.4971\n",
      "\n",
      "Epoch 00040: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0040.hdf5\n",
      "Epoch 41/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7162 - kullback_leibler_divergence: 3.6620 - accuracy: 0.5950 - val_loss: 0.8152 - val_kullback_leibler_divergence: 3.2172 - val_accuracy: 0.5007\n",
      "\n",
      "Epoch 00041: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0041.hdf5\n",
      "Epoch 42/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7119 - kullback_leibler_divergence: 3.7000 - accuracy: 0.5951 - val_loss: 0.8330 - val_kullback_leibler_divergence: 3.3165 - val_accuracy: 0.4996\n",
      "\n",
      "Epoch 00042: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0042.hdf5\n",
      "Epoch 43/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7104 - kullback_leibler_divergence: 3.6978 - accuracy: 0.5995 - val_loss: 0.8361 - val_kullback_leibler_divergence: 3.4403 - val_accuracy: 0.4982\n",
      "\n",
      "Epoch 00043: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0043.hdf5\n",
      "Epoch 44/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7079 - kullback_leibler_divergence: 3.7739 - accuracy: 0.6006 - val_loss: 0.8361 - val_kullback_leibler_divergence: 3.4048 - val_accuracy: 0.4964\n",
      "\n",
      "Epoch 00044: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0044.hdf5\n",
      "Epoch 45/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7091 - kullback_leibler_divergence: 3.8082 - accuracy: 0.5956 - val_loss: 0.8343 - val_kullback_leibler_divergence: 3.3445 - val_accuracy: 0.4953\n",
      "\n",
      "Epoch 00045: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0045.hdf5\n",
      "Epoch 46/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7078 - kullback_leibler_divergence: 3.8414 - accuracy: 0.5967 - val_loss: 0.8295 - val_kullback_leibler_divergence: 3.4157 - val_accuracy: 0.5014\n",
      "\n",
      "Epoch 00046: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0046.hdf5\n",
      "Epoch 47/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7051 - kullback_leibler_divergence: 3.8380 - accuracy: 0.6043 - val_loss: 0.8345 - val_kullback_leibler_divergence: 3.4456 - val_accuracy: 0.5022\n",
      "\n",
      "Epoch 00047: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0047.hdf5\n",
      "Epoch 48/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.7046 - kullback_leibler_divergence: 3.8599 - accuracy: 0.6031 - val_loss: 0.8386 - val_kullback_leibler_divergence: 3.3864 - val_accuracy: 0.4921\n",
      "\n",
      "Epoch 00048: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0048.hdf5\n",
      "Epoch 49/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7040 - kullback_leibler_divergence: 3.8438 - accuracy: 0.6048 - val_loss: 0.8413 - val_kullback_leibler_divergence: 3.3890 - val_accuracy: 0.4885\n",
      "\n",
      "Epoch 00049: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0049.hdf5\n",
      "Epoch 50/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.7045 - kullback_leibler_divergence: 3.8286 - accuracy: 0.6037 - val_loss: 0.8372 - val_kullback_leibler_divergence: 3.5471 - val_accuracy: 0.4946\n",
      "\n",
      "Epoch 00050: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0050.hdf5\n",
      "Epoch 51/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6907 - kullback_leibler_divergence: 3.9100 - accuracy: 0.6186 - val_loss: 0.8413 - val_kullback_leibler_divergence: 3.5057 - val_accuracy: 0.4989\n",
      "\n",
      "Epoch 00051: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0051.hdf5\n",
      "Epoch 52/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6925 - kullback_leibler_divergence: 3.9061 - accuracy: 0.6116 - val_loss: 0.8419 - val_kullback_leibler_divergence: 3.4894 - val_accuracy: 0.5018\n",
      "\n",
      "Epoch 00052: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0052.hdf5\n",
      "Epoch 53/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6902 - kullback_leibler_divergence: 3.8905 - accuracy: 0.6139 - val_loss: 0.8433 - val_kullback_leibler_divergence: 3.5094 - val_accuracy: 0.5004\n",
      "\n",
      "Epoch 00053: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0053.hdf5\n",
      "Epoch 54/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6906 - kullback_leibler_divergence: 3.9059 - accuracy: 0.6113 - val_loss: 0.8431 - val_kullback_leibler_divergence: 3.4931 - val_accuracy: 0.4986\n",
      "\n",
      "Epoch 00054: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0054.hdf5\n",
      "Epoch 55/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6900 - kullback_leibler_divergence: 3.9328 - accuracy: 0.6173 - val_loss: 0.8428 - val_kullback_leibler_divergence: 3.4887 - val_accuracy: 0.4978\n",
      "\n",
      "Epoch 00055: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0055.hdf5\n",
      "Epoch 56/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6903 - kullback_leibler_divergence: 3.9140 - accuracy: 0.6153 - val_loss: 0.8438 - val_kullback_leibler_divergence: 3.5033 - val_accuracy: 0.5014\n",
      "\n",
      "Epoch 00056: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0056.hdf5\n",
      "Epoch 57/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6901 - kullback_leibler_divergence: 3.9461 - accuracy: 0.6154 - val_loss: 0.8442 - val_kullback_leibler_divergence: 3.5161 - val_accuracy: 0.4996\n",
      "\n",
      "Epoch 00057: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0057.hdf5\n",
      "Epoch 58/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6899 - kullback_leibler_divergence: 3.9583 - accuracy: 0.6180 - val_loss: 0.8464 - val_kullback_leibler_divergence: 3.5066 - val_accuracy: 0.4996\n",
      "\n",
      "Epoch 00058: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0058.hdf5\n",
      "Epoch 59/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6861 - kullback_leibler_divergence: 3.9565 - accuracy: 0.6179 - val_loss: 0.8469 - val_kullback_leibler_divergence: 3.5264 - val_accuracy: 0.4971\n",
      "\n",
      "Epoch 00059: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0059.hdf5\n",
      "Epoch 60/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6918 - kullback_leibler_divergence: 3.9776 - accuracy: 0.6189 - val_loss: 0.8449 - val_kullback_leibler_divergence: 3.5144 - val_accuracy: 0.4968\n",
      "\n",
      "Epoch 00060: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0060.hdf5\n",
      "Epoch 61/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6908 - kullback_leibler_divergence: 3.9683 - accuracy: 0.6147 - val_loss: 0.8454 - val_kullback_leibler_divergence: 3.5217 - val_accuracy: 0.4942\n",
      "\n",
      "Epoch 00061: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0061.hdf5\n",
      "Epoch 62/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6888 - kullback_leibler_divergence: 3.9529 - accuracy: 0.6170 - val_loss: 0.8464 - val_kullback_leibler_divergence: 3.5245 - val_accuracy: 0.4986\n",
      "\n",
      "Epoch 00062: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0062.hdf5\n",
      "Epoch 63/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6861 - kullback_leibler_divergence: 3.9794 - accuracy: 0.6192 - val_loss: 0.8474 - val_kullback_leibler_divergence: 3.5769 - val_accuracy: 0.5007\n",
      "\n",
      "Epoch 00063: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0063.hdf5\n",
      "Epoch 64/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6861 - kullback_leibler_divergence: 4.0229 - accuracy: 0.6144 - val_loss: 0.8468 - val_kullback_leibler_divergence: 3.5539 - val_accuracy: 0.4986\n",
      "\n",
      "Epoch 00064: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0064.hdf5\n",
      "Epoch 65/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6835 - kullback_leibler_divergence: 4.0178 - accuracy: 0.6222 - val_loss: 0.8492 - val_kullback_leibler_divergence: 3.5527 - val_accuracy: 0.4975\n",
      "\n",
      "Epoch 00065: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0065.hdf5\n",
      "Epoch 66/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6853 - kullback_leibler_divergence: 4.0378 - accuracy: 0.6170 - val_loss: 0.8499 - val_kullback_leibler_divergence: 3.5664 - val_accuracy: 0.4924\n",
      "\n",
      "Epoch 00066: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0066.hdf5\n",
      "Epoch 67/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6855 - kullback_leibler_divergence: 4.0400 - accuracy: 0.6192 - val_loss: 0.8505 - val_kullback_leibler_divergence: 3.5746 - val_accuracy: 0.4928\n",
      "\n",
      "Epoch 00067: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0067.hdf5\n",
      "Epoch 68/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6871 - kullback_leibler_divergence: 4.0247 - accuracy: 0.6163 - val_loss: 0.8494 - val_kullback_leibler_divergence: 3.5740 - val_accuracy: 0.4928\n",
      "\n",
      "Epoch 00068: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0068.hdf5\n",
      "Epoch 69/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6886 - kullback_leibler_divergence: 4.0441 - accuracy: 0.6163 - val_loss: 0.8487 - val_kullback_leibler_divergence: 3.5642 - val_accuracy: 0.4949\n",
      "\n",
      "Epoch 00069: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0069.hdf5\n",
      "Epoch 70/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6861 - kullback_leibler_divergence: 4.0268 - accuracy: 0.6191 - val_loss: 0.8488 - val_kullback_leibler_divergence: 3.5657 - val_accuracy: 0.4986\n",
      "\n",
      "Epoch 00070: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0070.hdf5\n",
      "Epoch 71/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6872 - kullback_leibler_divergence: 4.0478 - accuracy: 0.6175 - val_loss: 0.8499 - val_kullback_leibler_divergence: 3.5855 - val_accuracy: 0.4971\n",
      "\n",
      "Epoch 00071: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0071.hdf5\n",
      "Epoch 72/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6804 - kullback_leibler_divergence: 4.0635 - accuracy: 0.6241 - val_loss: 0.8521 - val_kullback_leibler_divergence: 3.5776 - val_accuracy: 0.4986\n",
      "\n",
      "Epoch 00072: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0072.hdf5\n",
      "Epoch 73/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6848 - kullback_leibler_divergence: 4.0927 - accuracy: 0.6199 - val_loss: 0.8502 - val_kullback_leibler_divergence: 3.5979 - val_accuracy: 0.4964\n",
      "\n",
      "Epoch 00073: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0073.hdf5\n",
      "Epoch 74/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6847 - kullback_leibler_divergence: 4.0743 - accuracy: 0.6177 - val_loss: 0.8523 - val_kullback_leibler_divergence: 3.6232 - val_accuracy: 0.4957\n",
      "\n",
      "Epoch 00074: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0074.hdf5\n",
      "Epoch 75/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6840 - kullback_leibler_divergence: 4.0901 - accuracy: 0.6214 - val_loss: 0.8519 - val_kullback_leibler_divergence: 3.6229 - val_accuracy: 0.4921\n",
      "\n",
      "Epoch 00075: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0075.hdf5\n",
      "Epoch 76/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6888 - kullback_leibler_divergence: 4.0752 - accuracy: 0.6147 - val_loss: 0.8510 - val_kullback_leibler_divergence: 3.6166 - val_accuracy: 0.4895\n",
      "\n",
      "Epoch 00076: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0076.hdf5\n",
      "Epoch 77/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6816 - kullback_leibler_divergence: 4.1017 - accuracy: 0.6225 - val_loss: 0.8530 - val_kullback_leibler_divergence: 3.6239 - val_accuracy: 0.4903\n",
      "\n",
      "Epoch 00077: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0077.hdf5\n",
      "Epoch 78/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6854 - kullback_leibler_divergence: 4.1123 - accuracy: 0.6182 - val_loss: 0.8513 - val_kullback_leibler_divergence: 3.6006 - val_accuracy: 0.4928\n",
      "\n",
      "Epoch 00078: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0078.hdf5\n",
      "Epoch 79/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6816 - kullback_leibler_divergence: 4.1055 - accuracy: 0.6201 - val_loss: 0.8529 - val_kullback_leibler_divergence: 3.6208 - val_accuracy: 0.4924\n",
      "\n",
      "Epoch 00079: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0079.hdf5\n",
      "Epoch 80/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6822 - kullback_leibler_divergence: 4.1065 - accuracy: 0.6208 - val_loss: 0.8535 - val_kullback_leibler_divergence: 3.6257 - val_accuracy: 0.4924\n",
      "\n",
      "Epoch 00080: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0080.hdf5\n",
      "Epoch 81/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6854 - kullback_leibler_divergence: 4.1092 - accuracy: 0.6216 - val_loss: 0.8532 - val_kullback_leibler_divergence: 3.6260 - val_accuracy: 0.4953\n",
      "\n",
      "Epoch 00081: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0081.hdf5\n",
      "Epoch 82/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6804 - kullback_leibler_divergence: 4.1208 - accuracy: 0.6232 - val_loss: 0.8537 - val_kullback_leibler_divergence: 3.6254 - val_accuracy: 0.4953\n",
      "\n",
      "Epoch 00082: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0082.hdf5\n",
      "Epoch 83/100\n",
      "722/722 [==============================] - 12s 16ms/step - loss: 0.6850 - kullback_leibler_divergence: 4.1030 - accuracy: 0.6235 - val_loss: 0.8530 - val_kullback_leibler_divergence: 3.6121 - val_accuracy: 0.4949\n",
      "\n",
      "Epoch 00083: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0083.hdf5\n",
      "Epoch 84/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6848 - kullback_leibler_divergence: 4.1135 - accuracy: 0.6231 - val_loss: 0.8534 - val_kullback_leibler_divergence: 3.6078 - val_accuracy: 0.4942\n",
      "\n",
      "Epoch 00084: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0084.hdf5\n",
      "Epoch 85/100\n",
      "722/722 [==============================] - 12s 17ms/step - loss: 0.6821 - kullback_leibler_divergence: 4.0885 - accuracy: 0.6196 - val_loss: 0.8541 - val_kullback_leibler_divergence: 3.6188 - val_accuracy: 0.4942\n",
      "\n",
      "Epoch 00085: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0085.hdf5\n",
      "Epoch 86/100\n",
      "722/722 [==============================] - 11s 16ms/step - loss: 0.6798 - kullback_leibler_divergence: 4.1282 - accuracy: 0.6235 - val_loss: 0.8547 - val_kullback_leibler_divergence: 3.6465 - val_accuracy: 0.4978\n",
      "\n",
      "Epoch 00086: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0086.hdf5\n",
      "Epoch 87/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6808 - kullback_leibler_divergence: 4.1391 - accuracy: 0.6280 - val_loss: 0.8568 - val_kullback_leibler_divergence: 3.6709 - val_accuracy: 0.4975\n",
      "\n",
      "Epoch 00087: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0087.hdf5\n",
      "Epoch 88/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6799 - kullback_leibler_divergence: 4.1634 - accuracy: 0.6251 - val_loss: 0.8560 - val_kullback_leibler_divergence: 3.6568 - val_accuracy: 0.4957\n",
      "\n",
      "Epoch 00088: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0088.hdf5\n",
      "Epoch 89/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6844 - kullback_leibler_divergence: 4.1410 - accuracy: 0.6222 - val_loss: 0.8553 - val_kullback_leibler_divergence: 3.6314 - val_accuracy: 0.4939\n",
      "\n",
      "Epoch 00089: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0089.hdf5\n",
      "Epoch 90/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6810 - kullback_leibler_divergence: 4.1435 - accuracy: 0.6189 - val_loss: 0.8542 - val_kullback_leibler_divergence: 3.6510 - val_accuracy: 0.4964\n",
      "\n",
      "Epoch 00090: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0090.hdf5\n",
      "Epoch 91/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6814 - kullback_leibler_divergence: 4.1365 - accuracy: 0.6208 - val_loss: 0.8542 - val_kullback_leibler_divergence: 3.6339 - val_accuracy: 0.5014\n",
      "\n",
      "Epoch 00091: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0091.hdf5\n",
      "Epoch 92/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6825 - kullback_leibler_divergence: 4.1271 - accuracy: 0.6206 - val_loss: 0.8542 - val_kullback_leibler_divergence: 3.6507 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00092: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0092.hdf5\n",
      "Epoch 93/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6803 - kullback_leibler_divergence: 4.1803 - accuracy: 0.6199 - val_loss: 0.8547 - val_kullback_leibler_divergence: 3.6834 - val_accuracy: 0.4978\n",
      "\n",
      "Epoch 00093: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0093.hdf5\n",
      "Epoch 94/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6806 - kullback_leibler_divergence: 4.1477 - accuracy: 0.6240 - val_loss: 0.8556 - val_kullback_leibler_divergence: 3.6676 - val_accuracy: 0.4953\n",
      "\n",
      "Epoch 00094: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0094.hdf5\n",
      "Epoch 95/100\n",
      "722/722 [==============================] - 11s 16ms/step - loss: 0.6811 - kullback_leibler_divergence: 4.1912 - accuracy: 0.6218 - val_loss: 0.8543 - val_kullback_leibler_divergence: 3.6521 - val_accuracy: 0.5018\n",
      "\n",
      "Epoch 00095: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0095.hdf5\n",
      "Epoch 96/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6814 - kullback_leibler_divergence: 4.1673 - accuracy: 0.6204 - val_loss: 0.8551 - val_kullback_leibler_divergence: 3.6523 - val_accuracy: 0.4986\n",
      "\n",
      "Epoch 00096: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0096.hdf5\n",
      "Epoch 97/100\n",
      "722/722 [==============================] - 11s 16ms/step - loss: 0.6766 - kullback_leibler_divergence: 4.1597 - accuracy: 0.6288 - val_loss: 0.8575 - val_kullback_leibler_divergence: 3.6649 - val_accuracy: 0.4982\n",
      "\n",
      "Epoch 00097: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0097.hdf5\n",
      "Epoch 98/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6835 - kullback_leibler_divergence: 4.1842 - accuracy: 0.6201 - val_loss: 0.8544 - val_kullback_leibler_divergence: 3.6512 - val_accuracy: 0.4975\n",
      "\n",
      "Epoch 00098: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0098.hdf5\n",
      "Epoch 99/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6812 - kullback_leibler_divergence: 4.1680 - accuracy: 0.6231 - val_loss: 0.8565 - val_kullback_leibler_divergence: 3.6951 - val_accuracy: 0.4978\n",
      "\n",
      "Epoch 00099: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0099.hdf5\n",
      "Epoch 100/100\n",
      "722/722 [==============================] - 11s 15ms/step - loss: 0.6794 - kullback_leibler_divergence: 4.1715 - accuracy: 0.6230 - val_loss: 0.8570 - val_kullback_leibler_divergence: 3.6872 - val_accuracy: 0.4964\n",
      "\n",
      "Epoch 00100: saving model to Benchmark/trained_models/LSTM_univariate2_classification____0100.hdf5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "my_LSTM_model = LSTM_model()\n",
    "my_LSTM_model.compile(\n",
    "    optimizer=Adam(\n",
    "        learning_rate=0.05\n",
    "    ),\n",
    "    loss=SparseCategoricalCrossentropy(from_logits=False),\n",
    "#     loss='accuracy',\n",
    "    metrics=['kullback_leibler_divergence', 'accuracy'],\n",
    ")\n",
    "\n",
    "history = my_LSTM_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    callbacks=[\n",
    "        # earlyStopping(),\n",
    "        LearningRateScheduler(learning_rate_scheduler),\n",
    "        model_checkpoints,\n",
    "        tf.keras.callbacks.TerminateOnNaN()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "maritime-stanley",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'Benchmark/trained_models/{name}____history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "military-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'my_LSTM_model' not in globals():\n",
    "    model_last = sorted([i for i in os.listdir('Benchmark/trained_models/') if name in i and 'hdf5' in i])[-1]\n",
    "    my_LSTM_model = tf.keras.models.load_model(\n",
    "        os.path.join('Benchmark/trained_models', model_last),\n",
    "        custom_objects={'kl_divergence': kullback_leibler_divergence}\n",
    "    )\n",
    "if 'history' not in globals():\n",
    "    with open(f'Benchmark/trained_models/{name}____history.pkl', 'rb') as f:\n",
    "        history = pickle.load(f)\n",
    "if hasattr(history, 'history'):\n",
    "    history = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-publisher",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['accuracy'], label='train')\n",
    "plt.plot(history['val_accuracy'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-import",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['kullback_leibler_divergence'], label='train')\n",
    "plt.plot(history['val_kullback_leibler_divergence'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_learn_rate_plot(\n",
    "    my_LSTM_model,\n",
    "    X_train[..., :1],\n",
    "    y_train,\n",
    "    10**-6,\n",
    "    10**1,\n",
    "    100,\n",
    "    batch_size=64,\n",
    "    steps_per_epoch=1,\n",
    "    custom_objects={'kl_divergence': kullback_leibler_divergence}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-madness",
   "metadata": {},
   "source": [
    "## Econmetric measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-reward",
   "metadata": {},
   "source": [
    "Definition of cumulated returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulated_return(y_pred, ret, start_capital=1000, dtype=None):\n",
    "    assert y_pred.flatten().shape == ret.flatten().shape\n",
    "    balance = [start_capital]\n",
    "    signal = 0\n",
    "    for i, d in enumerate(y_pred[:-1]):\n",
    "        signal = signal if d == 1 else d\n",
    "        if signal == 0:\n",
    "            balance.append(balance[-1])\n",
    "        elif signal == 2:\n",
    "            balance.append(balance[-1] * ret[i])\n",
    "        else:\n",
    "            raise ValueError()\n",
    "    balance = np.array(balance, dtype=dtype)\n",
    "    return balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!! for testing purposes\n",
    "tmp_type = 'train'\n",
    "\n",
    "X = np.concatenate([sc.inverse_transform(i)[np.newaxis] for i in eval(f\"X_{tmp_type}\")], axis=0)\n",
    "for i in range(lag):\n",
    "    diff = np.abs(df.loc[eval(f\"index_{tmp_type}\")].iloc[i:-(lag - i + 1)].values - X[:,-(lag - i)]).sum(axis=0)\n",
    "    assert diff[0] < 1e-6 and diff[1] < 0.5, 'df and X inversed are not the same'\n",
    "\n",
    "X_ret_testing = np.concatenate([sc.inverse_transform(i)[np.newaxis] for i in eval(f\"X_{tmp_type}\")], axis=0)[:, -1, 0]\n",
    "y_testing = np.concatenate([sc.inverse_transform(i)[np.newaxis] for i in eval(f\"X_{tmp_type}\")], axis=0)[:, -1, 1]\n",
    "\n",
    "a = sc_target.inverse_transform(eval(f\"y_{tmp_type}\")).flatten()\n",
    "b = np.concatenate([sc.inverse_transform(i)[np.newaxis] for i in eval(f\"X_{tmp_type}\")], axis=0)[:, -1, 1]\n",
    "cc = df.loc[eval(f\"index_{tmp_type}\")].iloc[127:-2, 1].values\n",
    "print(np.abs(cc[1:] - a[:-1]).sum(axis=0))\n",
    "print(np.abs(cc - b).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((index_train[0:-129] == X_train_index[:, 0]).all())\n",
    "print((index_train[127:-2] == X_train_index[:, -1]).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-hughes",
   "metadata": {},
   "source": [
    "## read in data for econmic metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_type = 'train'\n",
    "X_ret_testing = np.concatenate([sc.inverse_transform(i)[np.newaxis] for i in eval(f\"X_{tmp_type}\")], axis=0)[:, -1, 0] + 1\n",
    "y_testing = np.concatenate([sc.inverse_transform(i)[np.newaxis] for i in eval(f\"X_{tmp_type}\")], axis=0)[:, -1, 1].round()\n",
    "\n",
    "df_testing = df.loc[eval(f\"index_{tmp_type}\")].iloc[127:-2]\n",
    "df_close_testing = df_close.loc[eval(f\"index_{tmp_type}\")].iloc[127:-2]\n",
    "X_ret_testing.shape[0] == df_testing.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.abs(cumulated_return(y_testing, X_ret_testing) - \\\n",
    "              cumulated_return(df_testing.values[:, 1], df_testing.values[:, 0] + 1)).sum() < 1e-10, \"cumulated return of df and X are not the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-feeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test eq\n",
    "print((np.equal((y_testing.flatten() == 0), X_ret_testing -1 < - 0.00000001)).mean())\n",
    "print((np.equal((y_testing.flatten() == 1), np.logical_and(X_ret_testing -1 >= -0.00000001, X_ret_testing -1 < 0.00000001 ))).mean())\n",
    "print((np.equal((y_testing.flatten() == 2), X_ret_testing -1 >= 0.00000001)).mean())\n",
    "\n",
    "print((np.equal((df_testing.values[:, 1] == 0), df_testing.values[:, 0] < -0.00000001)).mean())\n",
    "print((np.equal((df_testing.values[:, 1] == 1), np.logical_and(df_testing.values[:, 0] >= -0.00000001, df_testing.values[:, 0] < 0.00000001 ))).mean())\n",
    "print((np.equal((df_testing.values[:, 1] == 2), df_testing.values[:, 0] >= 0.00000001)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-literature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = predictions(\n",
    "#     my_LSTM_model,\n",
    "#     eval(f\"X_{tmp_type}\")[..., :1]\n",
    "# )\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "from copy import deepcopy\n",
    "y_pred = deepcopy(y_testing)\n",
    "np.random.shuffle(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    np.random.shuffle(y_pred)\n",
    "    plt.plot(cumulated_return(y_pred, X_ret_testing, 1000), color='grey', lw=0.5)\n",
    "a = cumulated_return(y_testing, X_ret_testing, 1000)\n",
    "plt.plot(a[1:], label='cumulated_return')\n",
    "a = cumulated_return(y_train, X_ret_testing, 1000)\n",
    "plt.plot(a[1:], label='y_train')\n",
    "plt.semilogy()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tmp_type == 'train':\n",
    "    df_tmp = df.loc[X_train_index[:, -1]].loc[:, target].values + 1\n",
    "    df_close_tmp = df_close.loc[X_train_index[:, -1]].iloc[:, target_column : target_column + 1].values\n",
    "    print(df_close_tmp[-1] / df_close_tmp[0] * 1000)\n",
    "    print(df_tmp.prod() * 1000)\n",
    "    print(X_ret_testing.prod() * 1000)\n",
    "    print(cumulated_return(y_testing * 0 + 2, X_ret_testing, 1000)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_ret_testing[1::3].prod()* 1000)\n",
    "y_tmp = y_testing[1:] * 1\n",
    "y_tmp[1::3] = 2\n",
    "print(cumulated_return(y_tmp, X_ret_testing[1:], 1000)[-1])\n",
    "y_tmp = y_train * 1\n",
    "y_tmp[1::3] = 2\n",
    "print(cumulated_return(y_tmp[:-1], X_ret_testing[1:], 1000)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_type = 'train'\n",
    "print(tmp_type)\n",
    "\n",
    "y = eval(f\"y_{tmp_type}\")\n",
    "y_pred = np.argmax(predictions(\n",
    "    my_LSTM_model,\n",
    "    eval(f\"X_{tmp_type}\")[..., :1]\n",
    "), axis=1)\n",
    "# actual_pred_plot(y_pred, eval(f'y_{tmp_type}'))\n",
    "# plt.show()\n",
    "print(f'Accuracy: {Accuracy()(y.flatten(), y_pred.flatten()).numpy()}')\n",
    "print(f'Accuracy: {SparseCategoricalAccuracy()(y.astype(dtype), y_pred.reshape(y.shape).astype(dtype)).numpy()}')\n",
    "print(f'KL_Divergence: {kullback_leibler_divergence(y.flatten().astype(dtype), y_pred.flatten().astype(dtype)).numpy()}')\n",
    "print(classification_report(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "X_ret = sc.inverse_transform(eval(f\"X_{tmp_type}\"))[:, -1, 0] + 1\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y_pred[:-1], X_ret[1:], dtype=dtype), label='predicted')\n",
    "\n",
    "p = [i[1]/y.shape[0] for i in sorted(Counter(y.flatten()).items(), key=lambda x: x[0])]\n",
    "x = np.concatenate(\n",
    "    [\n",
    "        cumulated_return(\n",
    "            np.random.choice([0, 1, 2], size=y_pred[:-1].shape, p=p),\n",
    "            X_ret[1:],\n",
    "            dtype=dtype\n",
    "        )[:,np.newaxis] for i in range(50)\n",
    "    ], axis=-1\n",
    ")\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], x.mean(axis=-1), label='random', color='gray')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], x.mean(axis=-1) + x.std(axis=-1), label='random_q75', color='gray', linestyle='--')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y_pred[:-1] * 0 + 2, X_ret[1:], dtype=dtype), label='buy&HODL')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y[:-1], X_ret[1:], dtype=dtype), label='oracle')\n",
    "plt.legend()\n",
    "plt.semilogy()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_type = 'val'\n",
    "print(tmp_type)\n",
    "\n",
    "y = eval(f\"y_{tmp_type}\")\n",
    "y_pred = np.argmax(predictions(\n",
    "    my_LSTM_model,\n",
    "    eval(f\"X_{tmp_type}\")[..., :1]\n",
    "), axis=1)\n",
    "# actual_pred_plot(y_pred, eval(f'y_{tmp_type}'))\n",
    "# plt.show()\n",
    "print(f'Accuracy: {Accuracy()(y.flatten(), y_pred.flatten()).numpy()}')\n",
    "print(f'Accuracy: {SparseCategoricalAccuracy()(y.astype(dtype), y_pred.reshape(y.shape).astype(dtype)).numpy()}')\n",
    "print(f'KL_Divergence: {kullback_leibler_divergence(y.flatten().astype(dtype), y_pred.flatten().astype(dtype)).numpy()}')\n",
    "print(classification_report(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "X_ret = sc.inverse_transform(eval(f\"X_{tmp_type}\"))[:, -1, 0] + 1\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y_pred[:-1], X_ret[1:], dtype=dtype), label='predicted')\n",
    "\n",
    "p = [i[1]/y.shape[0] for i in sorted(Counter(y.flatten()).items(), key=lambda x: x[0])]\n",
    "x = np.concatenate(\n",
    "    [\n",
    "        cumulated_return(\n",
    "            np.random.choice([0, 1, 2], size=y_pred[:-1].shape, p=p),\n",
    "            X_ret[1:],\n",
    "            dtype=dtype\n",
    "        )[:,np.newaxis] for i in range(50)\n",
    "    ], axis=-1\n",
    ")\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], x.mean(axis=-1), label='random', color='gray')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], x.mean(axis=-1) + x.std(axis=-1), label='random_q75', color='gray', linestyle='--')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y_pred[:-1] * 0 + 2, X_ret[1:], dtype=dtype), label='buy&HODL')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y[:-1], X_ret[1:], dtype=dtype), label='oracle')\n",
    "plt.legend()\n",
    "plt.semilogy()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-crest",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_type = 'test'\n",
    "print(tmp_type)\n",
    "\n",
    "y = eval(f\"y_{tmp_type}\")\n",
    "y_pred = np.argmax(predictions(\n",
    "    my_LSTM_model,\n",
    "    eval(f\"X_{tmp_type}\")[..., :1]\n",
    "), axis=1)\n",
    "# actual_pred_plot(y_pred, eval(f'y_{tmp_type}'))\n",
    "# plt.show()\n",
    "print(f'Accuracy: {Accuracy()(y.flatten(), y_pred.flatten()).numpy()}')\n",
    "print(f'Accuracy: {SparseCategoricalAccuracy()(y.astype(dtype), y_pred.reshape(y.shape).astype(dtype)).numpy()}')\n",
    "print(f'KL_Divergence: {kullback_leibler_divergence(y.flatten().astype(dtype), y_pred.flatten().astype(dtype)).numpy()}')\n",
    "print(classification_report(y, y_pred))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "\n",
    "X_ret = sc.inverse_transform(eval(f\"X_{tmp_type}\"))[:, -1, 0] + 1\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y_pred[:-1], X_ret[1:], dtype=dtype), label='predicted')\n",
    "\n",
    "p = [i[1]/y.shape[0] for i in sorted(Counter(y.flatten()).items(), key=lambda x: x[0])]\n",
    "x = np.concatenate(\n",
    "    [\n",
    "        cumulated_return(\n",
    "            np.random.choice([0, 1, 2], size=y_pred[:-1].shape, p=p),\n",
    "            X_ret[1:],\n",
    "            dtype=dtype\n",
    "        )[:,np.newaxis] for i in range(50)\n",
    "    ], axis=-1\n",
    ")\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], x.mean(axis=-1), label='random', color='gray')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], x.mean(axis=-1) + x.std(axis=-1), label='random_q75', color='gray', linestyle='--')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y_pred[:-1] * 0 + 2, X_ret[1:], dtype=dtype), label='buy&HODL')\n",
    "plt.plot(eval(f\"index_{tmp_type}\")[127:-2][1:], cumulated_return(y[:-1], X_ret[1:], dtype=dtype), label='oracle')\n",
    "plt.legend()\n",
    "plt.semilogy()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-ethics",
   "metadata": {},
   "source": [
    "cumulated_return(y_pred, X_ret, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cumulated_return(y_pred[:-1], X_ret[1:], dtype=dtype)\n",
    "\n",
    "(x[-1] / x[0]) / (np.std(x[1:] / x[:-1]) * np.sqrt(6 * 24 * 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax1 = fig.add_subplot(211)\n",
    "# ax1.plot(index_train[X_train.shape[1]:], df_train[target], label='Training data')\n",
    "# ax1.plot(index_val[X_train.shape[1]:], df_val[target], label='Validation data')\n",
    "# ax1.plot(index_test[X_train.shape[1]:], df_test[target], label='Test data')\n",
    "# ax1.set_xlabel('Dates')\n",
    "# ax1.set_ylabel('Normalized Closing Returns')\n",
    "# ax1.set_title(\"Close Price\", fontsize=18)\n",
    "# ax1.legend(loc=\"best\", fontsize=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fxpred3",
   "language": "python",
   "name": "fxpred3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
