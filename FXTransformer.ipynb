{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "i6zxz6xZyWb2",
    "outputId": "a40e8d2a-f684-4a98-fb9e-237db53569be"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import os, datetime\n",
    "from utils import data_read_dict, data_read_concat, data_merge\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "print('Tensorflow version: {}'.format(tf.__version__))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "if platform.node() == \"msbq\":\n",
    "    from tensorflow.python.client import device_lib\n",
    "    print(device_lib.list_local_devices())\n",
    "    print(tf.__version__)\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "    tf.config.list_physical_devices('GPU')\n",
    "    !python --version\n",
    "\n",
    "#     tf.config.list_physical_devices('GPU')\n",
    "#     gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#     if gpus:\n",
    "#       # Restrict TensorFlow to only allocate 4GB of memory on the first GPU\n",
    "#       try:\n",
    "#         tf.config.experimental.set_virtual_device_configuration(\n",
    "#             gpus[0],\n",
    "#             [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#       except RuntimeError as e:\n",
    "#         # Virtual devices must be set before GPUs have been initialized\n",
    "#         print(e)\n",
    "#         print('asdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ykFSM9LT54LR"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Acgb31zy5lcD"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 128\n",
    "\n",
    "d_k = 256\n",
    "d_v = 256\n",
    "n_heads = 12\n",
    "ff_dim = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnPzNUPK50Ki"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "jdi13JvV5ltd",
    "outputId": "9ecf3ca3-1b11-4495-b240-505b9309698f"
   },
   "outputs": [],
   "source": [
    "IBM_path = 'content/10min Dataset.csv'\n",
    "\n",
    "# df = pd.read_csv(IBM_path, delimiter=';', usecols=['Dates', 'EURUSD BGNE Curncy Bid Open', 'EURUSD BGNE Curncy Bid Close', 'EURUSD BGNE Curncy Bid High', 'EURUSD BGNE Curncy Bid Low', 'EURUSD BGNE Curncy Bid Number Ticks', 'EURUSD BGNE Curncy Ask Open', 'EURUSD BGNE Curncy Ask Close', 'EURUSD BGNE Curncy Ask High', 'EURUSD BGNE Curncy Ask Low', 'EURUSD BGNE Curncy Ask Number Ticks', 'USDJPY BGNE Curncy Bid Open', 'USDJPY BGNE Curncy Bid Close', 'USDJPY BGNE Curncy Bid High', 'USDJPY BGNE Curncy Bid Low', 'USDJPY BGNE Curncy Bid Number Ticks', 'USDJPY BGNE Curncy Ask Open', 'USDJPY BGNE Curncy Ask Close', 'USDJPY BGNE Curncy Ask High', 'USDJPY BGNE Curncy Ask Low', 'USDJPY BGNE Curncy Ask Number Ticks', 'GBPUSD BGNE Curncy Bid Open', 'GBPUSD BGNE Curncy Bid Close', 'GBPUSD BGNE Curncy Bid High', 'GBPUSD BGNE Curncy Bid Low', 'GBPUSD BGNE Curncy Bid Number Ticks', 'GBPUSD BGNE Curncy Ask Open', 'GBPUSD BGNE Curncy Ask Close', 'GBPUSD BGNE Curncy Ask High', 'GBPUSD BGNE Curncy Ask Low', 'GBPUSD BGNE Curncy Ask Number Ticks', 'AUDUSD BGNE Curncy Bid Open', 'AUDUSD BGNE Curncy Bid Close', 'AUDUSD BGNE Curncy Bid High', 'AUDUSD BGNE Curncy Bid Low', 'AUDUSD BGNE Curncy Bid Number Ticks', 'AUDUSD BGNE Curncy Ask Open', 'AUDUSD BGNE Curncy Ask Close', 'AUDUSD BGNE Curncy Ask High', 'AUDUSD BGNE Curncy Ask Low', 'AUDUSD BGNE Curncy Ask Number Ticks', 'USDCAD BGNE Curncy Bid Open', 'USDCAD BGNE Curncy Bid Close', 'USDCAD BGNE Curncy Bid High', 'USDCAD BGNE Curncy Bid Low', 'USDCAD BGNE Curncy Bid Number Ticks', 'USDCAD BGNE Curncy Ask Open', 'USDCAD BGNE Curncy Ask Close', 'USDCAD BGNE Curncy Ask High', 'USDCAD BGNE Curncy Ask Low', 'USDCAD BGNE Curncy Ask Number Ticks', 'USDCHF BGNE Curncy Bid Open', 'USDCHF BGNE Curncy Bid Close', 'USDCHF BGNE Curncy Bid High', 'USDCHF BGNE Curncy Bid Low', 'USDCHF BGNE Curncy Bid Number Ticks', 'USDCHF BGNE Curncy Ask Open', 'USDCHF BGNE Curncy Ask Close', 'USDCHF BGNE Curncy Ask High', 'USDCHF BGNE Curncy Ask Low', 'USDCHF BGNE Curncy Ask Number Ticks', 'NZDUSD BGNE Curncy Bid Open', 'NZDUSD BGNE Curncy Bid Close', 'NZDUSD BGNE Curncy Bid High', 'NZDUSD BGNE Curncy Bid Low', 'NZDUSD BGNE Curncy Bid Number Ticks', 'NZDUSD BGNE Curncy Ask Open', 'NZDUSD BGNE Curncy Ask Close', 'NZDUSD BGNE Curncy Ask High', 'NZDUSD BGNE Curncy Ask Low', 'NZDUSD BGNE Curncy Ask Number Ticks', 'EURJPY BGNE Curncy Bid Open', 'EURJPY BGNE Curncy Bid Close', 'EURJPY BGNE Curncy Bid High', 'EURJPY BGNE Curncy Bid Low', 'EURJPY BGNE Curncy Bid Number Ticks', 'EURJPY BGNE Curncy Ask Open', 'EURJPY BGNE Curncy Ask Close', 'EURJPY BGNE Curncy Ask High', 'EURJPY BGNE Curncy Ask Low', 'EURJPY BGNE Curncy Ask Number Ticks', 'GBPJPY BGNE Curncy Bid Open', 'GBPJPY BGNE Curncy Bid Close', 'GBPJPY BGNE Curncy Bid High', 'GBPJPY BGNE Curncy Bid Low', 'GBPJPY BGNE Curncy Bid Number Ticks', 'GBPJPY BGNE Curncy Ask Open', 'GBPJPY BGNE Curncy Ask Close', 'GBPJPY BGNE Curncy Ask High', 'GBPJPY BGNE Curncy Ask Low', 'GBPJPY BGNE Curncy Ask Number Ticks', 'EURGBP BGNE Curncy Bid Open', 'EURGBP BGNE Curncy Bid Close', 'EURGBP BGNE Curncy Bid High', 'EURGBP BGNE Curncy Bid Low', 'EURGBP BGNE Curncy Bid Number Ticks', 'EURGBP BGNE Curncy Ask Open', 'EURGBP BGNE Curncy Ask Close', 'EURGBP BGNE Curncy Ask High', 'EURGBP BGNE Curncy Ask Low', 'EURGBP BGNE Curncy Ask Number Ticks', 'AUDJPY BGNE Curncy Bid Open', 'AUDJPY BGNE Curncy Bid Close', 'AUDJPY BGNE Curncy Bid High', 'AUDJPY BGNE Curncy Bid Low', 'AUDJPY BGNE Curncy Bid Number Ticks', 'AUDJPY BGNE Curncy Ask Open', 'AUDJPY BGNE Curncy Ask Close', 'AUDJPY BGNE Curncy Ask High', 'AUDJPY BGNE Curncy Ask Low', 'AUDJPY BGNE Curncy Ask Number Ticks', 'EURAUD BGNE Curncy Bid Open', 'EURAUD BGNE Curncy Bid Close', 'EURAUD BGNE Curncy Bid High', 'EURAUD BGNE Curncy Bid Low', 'EURAUD BGNE Curncy Bid Number Ticks', 'EURAUD BGNE Curncy Ask Open', 'EURAUD BGNE Curncy Ask Close', 'EURAUD BGNE Curncy Ask High', 'EURAUD BGNE Curncy Ask Low', 'EURAUD BGNE Curncy Ask Number Ticks', 'EURCHF BGNE Curncy Bid Open', 'EURCHF BGNE Curncy Bid Close', 'EURCHF BGNE Curncy Bid High', 'EURCHF BGNE Curncy Bid Low', 'EURCHF BGNE Curncy Bid Number Ticks', 'EURCHF BGNE Curncy Ask Open', 'EURCHF BGNE Curncy Ask Close', 'EURCHF BGNE Curncy Ask High', 'EURCHF BGNE Curncy Ask Low', 'EURCHF BGNE Curncy Ask Number Ticks', 'AUDNZD BGNE Curncy Bid Open', 'AUDNZD BGNE Curncy Bid Close', 'AUDNZD BGNE Curncy Bid High', 'AUDNZD BGNE Curncy Bid Low', 'AUDNZD BGNE Curncy Bid Number Ticks', 'AUDNZD BGNE Curncy Ask Open', 'AUDNZD BGNE Curncy Ask Close', 'AUDNZD BGNE Curncy Ask High', 'AUDNZD BGNE Curncy Ask Low', 'AUDNZD BGNE Curncy Ask Number Ticks', 'NZDJPY BGNE Curncy Bid Open', 'NZDJPY BGNE Curncy Bid Close', 'NZDJPY BGNE Curncy Bid High', 'NZDJPY BGNE Curncy Bid Low', 'NZDJPY BGNE Curncy Bid Number Ticks', 'NZDJPY BGNE Curncy Ask Open', 'NZDJPY BGNE Curncy Ask Close', 'NZDJPY BGNE Curncy Ask High', 'NZDJPY BGNE Curncy Ask Low', 'NZDJPY BGNE Curncy Ask Number Ticks', 'GBPAUD BGNE Curncy Bid Open', 'GBPAUD BGNE Curncy Bid Close', 'GBPAUD BGNE Curncy Bid High', 'GBPAUD BGNE Curncy Bid Low', 'GBPAUD BGNE Curncy Bid Number Ticks', 'GBPAUD BGNE Curncy Ask Open', 'GBPAUD BGNE Curncy Ask Close', 'GBPAUD BGNE Curncy Ask High', 'GBPAUD BGNE Curncy Ask Low', 'GBPAUD BGNE Curncy Ask Number Ticks', 'GBPCAD BGNE Curncy Bid Open', 'GBPCAD BGNE Curncy Bid Close', 'GBPCAD BGNE Curncy Bid High', 'GBPCAD BGNE Curncy Bid Low', 'GBPCAD BGNE Curncy Bid Number Ticks', 'GBPCAD BGNE Curncy Ask Open', 'GBPCAD BGNE Curncy Ask Close', 'GBPCAD BGNE Curncy Ask High', 'GBPCAD BGNE Curncy Ask Low', 'GBPCAD BGNE Curncy Ask Number Ticks', 'EURNZD BGNE Curncy Bid Open', 'EURNZD BGNE Curncy Bid Close', 'EURNZD BGNE Curncy Bid High', 'EURNZD BGNE Curncy Bid Low', 'EURNZD BGNE Curncy Bid Number Ticks', 'EURNZD BGNE Curncy Ask Open', 'EURNZD BGNE Curncy Ask Close', 'EURNZD BGNE Curncy Ask High', 'EURNZD BGNE Curncy Ask Low', 'EURNZD BGNE Curncy Ask Number Ticks', 'AUDCAD BGNE Curncy Bid Open', 'AUDCAD BGNE Curncy Bid Close', 'AUDCAD BGNE Curncy Bid High', 'AUDCAD BGNE Curncy Bid Low', 'AUDCAD BGNE Curncy Bid Number Ticks', 'AUDCAD BGNE Curncy Ask Open', 'AUDCAD BGNE Curncy Ask Close', 'AUDCAD BGNE Curncy Ask High', 'AUDCAD BGNE Curncy Ask Low', 'AUDCAD BGNE Curncy Ask Number Ticks', 'GBPCHF BGNE Curncy Bid Open', 'GBPCHF BGNE Curncy Bid Close', 'GBPCHF BGNE Curncy Bid High', 'GBPCHF BGNE Curncy Bid Low', 'GBPCHF BGNE Curncy Bid Number Ticks', 'GBPCHF BGNE Curncy Ask Open', 'GBPCHF BGNE Curncy Ask Close', 'GBPCHF BGNE Curncy Ask High', 'GBPCHF BGNE Curncy Ask Low', 'GBPCHF BGNE Curncy Ask Number Ticks', 'EURUSDV1M Curncy 44278 Open', 'USDJPYV1M Curncy  Open', 'GBPUSDV1M Curncy  Open', 'AUDUSDV1M Curncy  Open', 'USDCADV1M Curncy  Open', 'USDCHFV1M Curncy  Open', 'NZDUSDV1M Curncy  Open', 'EURJPYV1M Curncy  Open', 'GBPJPYV1M Curncy  Open', 'EURGBPV1M Curncy  Open', 'AUDJPYV1M Curncy  Open', 'EURAUDV1M Curncy  Open', 'EURCHFV1M Curncy  Open', 'AUDNZDV1M Curncy  Open', 'NZDJPYV1M Curncy  Open', 'GBPAUDV1M Curncy  Open', 'GBPCADV1M Curncy  Open', 'EURNZDV1M Curncy  Open', 'AUDCADV1M Curncy  Open', 'GBPCHFV1M Curncy  Open', 'EURUSDV3M Curncy Trade Open', 'USDJPYV3M Curncy Trade Open', 'GBPUSDV3M Curncy Trade Open', 'AUDUSDV3M Curncy Trade Open', 'USDCADV3M Curncy Trade Open', 'USDCHFV3M Curncy Trade Open', 'NZDUSDV3M Curncy Trade Open', 'EURJPYV3M Curncy Trade Open', 'GBPJPYV3M Curncy Trade Open', 'EURGBPV3M Curncy Trade Open', 'AUDJPYV3M Curncy Trade Open', 'EURAUDV3M Curncy Trade Open', 'EURCHFV3M Curncy Trade Open', 'AUDNZDV3M Curncy Trade Open', 'NZDJPYV3M Curncy Trade Open', 'GBPAUDV3M Curncy Trade Open', 'GBPCADV3M Curncy Trade Open', 'EURNZDV3M Curncy Trade Open', 'AUDCADV3M Curncy Trade Open', 'GBPCHFV3M Curncy Trade Open', 'EURUSDV1Y Curncy Trade Open', 'USDJPYV1Y Curncy Trade Open', 'GBPUSDV1Y Curncy Trade Open', 'AUDUSDV1Y Curncy Trade Open', 'USDCADV1Y Curncy Trade Open', 'USDCHFV1Y Curncy Trade Open', 'NZDUSDV1Y Curncy Trade Open', 'EURJPYV1Y Curncy Trade Open', 'GBPJPYV1Y Curncy Trade Open', 'EURGBPV1Y Curncy Trade Open', 'AUDJPYV1Y Curncy Trade Open', 'EURAUDV1Y Curncy Trade Open', 'EURCHFV1Y Curncy Trade Open', 'AUDNZDV1Y Curncy Trade Open', 'NZDJPYV1Y Curncy Trade Open', 'GBPAUDV1Y Curncy Trade Open', 'GBPCADV1Y Curncy Trade Open', 'EURNZDV1Y Curncy Trade Open', 'AUDCADV1Y Curncy Trade Open', 'GBPCHFV1Y Curncy Trade Open', 'EURUSD25R1M Curncy Trade Open', 'USDJPY25R1M Curncy Trade Open', 'GBPUSD25R1M Curncy Trade Open', 'AUDUSD25R1M Curncy Trade Open', 'USDCAD25R1M Curncy Trade Open', 'USDCHF25R1M Curncy Trade Open', 'NZDUSD25R1M Curncy Trade Open', 'EURJPY25R1M Curncy Trade Open', 'GBPJPY25R1M Curncy Trade Open', 'EURGBP25R1M Curncy Trade Open', 'AUDJPY25R1M Curncy Trade Open', 'EURAUD25R1M Curncy Trade Open', 'EURCHF25R1M Curncy Trade Open', 'AUDNZD25R1M Curncy Trade Open', 'NZDJPY25R1M Curncy Trade Open', 'GBPAUD25R1M Curncy Trade Open', 'GBPCAD25R1M Curncy Trade Open', 'EURNZD25R1M Curncy Trade Open', 'AUDCAD25R1M Curncy Trade Open', 'GBPCHF25R1M Curncy Trade Open', 'EURUSD25R3M Curncy 44278 Open', 'USDJPY25R3M Curncy  Open', 'GBPUSD25R3M Curncy  Open', 'AUDUSD25R3M Curncy  Open', 'USDCAD25R3M Curncy  Open', 'USDCHF25R3M Curncy  Open', 'NZDUSD25R3M Curncy  Open', 'EURJPY25R3M Curncy  Open', 'GBPJPY25R3M Curncy  Open', 'EURGBP25R3M Curncy  Open', 'AUDJPY25R3M Curncy  Open', 'EURAUD25R3M Curncy  Open', 'EURCHF25R3M Curncy  Open', 'AUDNZD25R3M Curncy  Open', 'NZDJPY25R3M Curncy  Open', 'GBPAUD25R3M Curncy  Open', 'GBPCAD25R3M Curncy  Open', 'EURNZD25R3M Curncy  Open', 'AUDCAD25R3M Curncy  Open', 'GBPCHF25R3M Curncy  Open', 'EURUSDCR Curncy Trade Open', 'USDJPYCR Curncy Trade Open', 'GBPUSDCR Curncy Trade Open', 'AUDUSDCR Curncy Trade Open', 'USDCADCR Curncy Trade Open', 'USDCHFCR Curncy Trade Open', 'NZDUSDCR Curncy Trade Open', 'EURJPYCR Curncy Trade Open', 'GBPJPYCR Curncy Trade Open', 'EURGBPCR Curncy Trade Open', 'AUDJPYCR Curncy Trade Open', 'EURAUDCR Curncy Trade Open', 'EURCHFCR Curncy Trade Open', 'AUDNZDCR Curncy Trade Open', 'NZDJPYCR Curncy Trade Open', 'GBPAUDCR Curncy Trade Open', 'GBPCADCR Curncy Trade Open', 'EURNZDCR Curncy Trade Open', 'AUDCADCR Curncy Trade Open', 'GBPCHFCR Curncy Trade Open', 'EURUSD1M Curncy Trade Open', 'USDJPY1M Curncy Trade Open', 'GBPUSD1M Curncy Trade Open', 'AUDUSD1M Curncy Trade Open', 'USDCAD1M Curncy Trade Open', 'USDCHF1M Curncy Trade Open', 'NZDUSD1M Curncy Trade Open', 'EURJPY1M Curncy Trade Open', 'GBPJPY1M Curncy Trade Open', 'EURGBP1M Curncy Trade Open', 'AUDJPY1M Curncy Trade Open', 'EURAUD1M Curncy Trade Open', 'EURCHF1M Curncy Trade Open', 'AUDNZD1M Curncy Trade Open', 'NZDJPY1M Curncy Trade Open', 'GBPAUD1M Curncy Trade Open', 'GBPCAD1M Curncy Trade Open', 'EURNZD1M Curncy Trade Open', 'AUDCAD1M Curncy Trade Open', 'GBPCHF1M Curncy Trade Open', 'EURUSD3M Curncy Trade Open', 'USDJPY3M Curncy Trade Open', 'GBPUSD3M Curncy Trade Open', 'AUDUSD3M Curncy Trade Open', 'USDCAD3M Curncy Trade Open', 'USDCHF3M Curncy Trade Open', 'NZDUSD3M Curncy Trade Open', 'EURJPY3M Curncy Trade Open', 'GBPJPY3M Curncy Trade Open', 'EURGBP3M Curncy Trade Open', 'AUDJPY3M Curncy Trade Open', 'EURAUD3M Curncy Trade Open', 'EURCHF3M Curncy Trade Open', 'AUDNZD3M Curncy Trade Open', 'NZDJPY3M Curncy Trade Open', 'GBPAUD3M Curncy Trade Open', 'GBPCAD3M Curncy Trade Open', 'EURNZD3M Curncy Trade Open', 'AUDCAD3M Curncy Trade Open', 'GBPCHF3M Curncy Trade Open', 'CL1 Comdty Trade Open', 'CO1 Comdty Trade Open', 'HG1 Comdty Trade Open', 'UXA1 Comdty Trade Open', 'NG1 Comdty Trade Open', 'GC1 Comdty Trade Open', 'LB1 Comdty Trade Open', 'C 1 Comdty Trade Open', 'S 1 Comdty Trade Open', 'HRC1 Comdty Trade Open', 'XB1 Comdty Trade Open', 'MO1 Comdty Trade Open', 'IOE1 Comdty Trade Open', 'SCO1 Comdty Trade Open', 'SB1 Comdty Trade Open', 'W 1 Comdty Trade Open', 'HO1 Comdty Trade Open', 'KO1 Comdty Trade Open', 'BO1 Comdty Trade Open', 'SI1 Comdty Trade Open', 'USSW10 BGN Curncy Trade Open', 'EUSA10 BGN Curncy Trade Open', 'USSW5 BGN Curncy Trade Open', 'USSW30 BGN Curncy Trade Open', 'USSP10 BGN Curncy Trade Open', 'USSWAP10 BGN Curncy Trade Open', 'EUSA5 BGN Curncy Trade Open', 'EUSA30 BGN Curncy Trade Open', 'USSP30 BGN Curncy Trade Open', 'USSW2 BGN Curncy Trade Open', 'USSWAP5 BGN Curncy Trade Open', 'EUSA20 BGN Curncy Trade Open', 'USSP5 BGN Curncy Trade Open', 'USSW3 BGN Curncy Trade Open', 'USSWIT10 BGN Curncy Trade Open', 'JYBSC BGN Curncy Trade Open', 'JYSW10 BGN Curncy Trade Open', 'ADSWAP10 BGN Curncy Trade Open', 'PZSW5 BGN Curncy Trade Open', 'ES1 Index Trade Open', 'NQ1 Index Trade Open', 'VG1 Index Trade Open', 'GX1 Index Trade Open', 'UX1 Index Trade Open', 'NK1 Index Trade Open', 'RTY1 Index Trade Open', 'XU1 Index Trade Open', 'MES1 Index Trade Open', 'DM1 Index Trade Open', 'TP1 Index Trade Open', 'NH1 Index Trade Open', 'IH1 Index Trade Open', 'XP1 Index Trade Open', 'SP1 Index Trade Open', 'Z 1 Index Trade Open', 'TY1 Comdty Trade Open', 'RX1 Comdty Trade Open', 'JB1 Comdty Trade Open', 'US1 Comdty Trade Open', 'IK1 Comdty Trade Open', 'ED1 Comdty Trade Open', 'WN1 Comdty Trade Open', 'YM1 Comdty Trade Open', 'FV1 Comdty Trade Open', 'G 1 Comdty Trade Open', 'UB1 Comdty Trade Open', 'FF1 Comdty Trade Open', 'OE1 Comdty Trade Open', 'TU1 Comdty Trade Open', 'KE1 Comdty Trade Open', 'DU1 Comdty Trade Open', 'UXY1 Comdty Trade Open', 'CN1 Comdty Trade Open', 'KAA1 Comdty Trade Open'])\n",
    "df = pd.read_csv(IBM_path, delimiter=';')\n",
    "\n",
    "# Replace 0 to avoid dividing by 0 later on\n",
    "df.replace(to_replace=0, method='ffill', inplace=True) \n",
    "df.drop('UXA1 Comdty Trade Open', axis=1, inplace=True)\n",
    "df['Dates'] = pd.to_datetime(df['Dates'], format='%d.%m.%y %H:%M')\n",
    "df.sort_values('Dates', inplace=True)\n",
    "df.sort_values('Dates')\n",
    "df.index = df['Dates']\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = data_merge(data_read_dict('data/bbg/'))\n",
    "df_metrics = df_metrics.iloc[::-1, :].bfill().iloc[::-1, :]\n",
    "df_metrics.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df, df_metrics, left_index=True, right_index=True, how='outer')\n",
    "df_merged = df_merged.loc[df_merged.index <= max(df.Dates),:]\n",
    "d = pd.isna(df_metrics).any(axis=1)\n",
    "df_merged = df_merged.loc[df_merged.index >= df_metrics.loc[~d].index.min()]\n",
    "df_merged.loc[~pd.isna(df_merged).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged[:]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Caac4a66588l"
   },
   "source": [
    "## Plot 10min EURUSD closing prices and volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "colab_type": "code",
    "id": "JJ1tN1_k5lx2",
    "outputId": "d3f82e93-5491-4ed0-a15c-77ed26035fa8"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "st = fig.suptitle(\"EURUSD Spot Rate\", fontsize=20)\n",
    "st.set_y(0.92)\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "# ax1.plot(df['EURUSD BGNE Curncy Bid Close'], label='EURUSD BGNE Curncy Bid Close')\n",
    "ax1.plot(df['Dates'], df['EURUSD BGNE Curncy Bid Close'], label='EURUSD BGNE Curncy Bid Close')\n",
    "#ax1.set_xticks(range(0, df.shape[0], 1464))\n",
    "#ax1.set_xticklabels(df['Dates'].loc[::1464])\n",
    "ax1.set_ylabel('Close Price', fontsize=18)\n",
    "ax1.legend(loc=\"upper left\", fontsize=12)\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "# ax2.plot(df['EURUSDV1Y Curncy Trade Open'], label='EURUSDV1Y Curncy Trade Open')\n",
    "ax2.plot(df['Dates'], df['EURUSDV1Y Curncy Trade Open'], label='EURUSDV1Y Curncy Trade Open')\n",
    "#ax2.set_xticks(range(0, df.shape[0], 1464))\n",
    "#ax2.set_xticklabels(df['Dates'].loc[::1464])\n",
    "ax2.set_ylabel('EURUSDV1Y Curncy Trade Open', fontsize=18)\n",
    "ax2.legend(loc=\"upper left\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTS3Cm2H6GBz"
   },
   "source": [
    "## Calculate normalized percentage change of all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate percentage change'''\n",
    "df = df.set_index('Dates')\n",
    "df.pct_change()\n",
    "\n",
    "df.dropna(how='any', axis=0, inplace=True) # Drop all rows with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Normalize price columns'''\n",
    "df = (df - df.mean()) / (df.max() - df.min())\n",
    "df.columns[np.isnan(df).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dropna(how='any', axis=0, inplace=True) # Drop all rows with NaN values\n",
    "#np.isinf(df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training, validation and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "i7_Uju9B5lqY",
    "outputId": "d99dba2b-8ac4-467c-da85-758445af29b1"
   },
   "outputs": [],
   "source": [
    "times = sorted(df.index.values)\n",
    "last_10pct = sorted(df.index.values)[-int(0.1*len(times))] # Last 10% of series\n",
    "last_20pct = sorted(df.index.values)[-int(0.2*len(times))] # Last 20% of series\n",
    "\n",
    "df_train = df[(df.index < last_20pct)]  # Training data are 80% of total data\n",
    "df_val = df[(df.index >= last_20pct) & (df.index < last_10pct)]\n",
    "df_test = df[(df.index >= last_10pct)]\n",
    "\n",
    "# Convert pandas columns into arrays\n",
    "train_data = df_train.values\n",
    "val_data = df_val.values\n",
    "test_data = df_test.values\n",
    "print('Training data shape: {}'.format(train_data.shape))\n",
    "print('Validation data shape: {}'.format(val_data.shape))\n",
    "print('Test data shape: {}'.format(test_data.shape))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "diGgUw_f6fAI"
   },
   "source": [
    "## Plot daily changes of close prices and volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 792
    },
    "colab_type": "code",
    "id": "MJCti1mt5lnL",
    "outputId": "5cd6ad72-c397-4271-cec6-17d354ed9264"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "st = fig.suptitle(\"Data Separation\", fontsize=20)\n",
    "st.set_y(0.95)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(np.arange(train_data.shape[0]), df_train['EURUSD BGNE Curncy Bid Close'], label='Training data')\n",
    "\n",
    "ax1.plot(np.arange(train_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]), df_val['EURUSD BGNE Curncy Bid Close'], label='Validation data')\n",
    "\n",
    "ax1.plot(np.arange(train_data.shape[0]+val_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]+test_data.shape[0]), df_test['EURUSD BGNE Curncy Bid Close'], label='Test data')\n",
    "ax1.set_xlabel('Dates')\n",
    "ax1.set_ylabel('Normalized Closing Returns')\n",
    "ax1.set_title(\"Close Price\", fontsize=18)\n",
    "ax1.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(np.arange(train_data.shape[0]), df_train['EURUSDV1Y Curncy Trade Open'], label='Training data')\n",
    "\n",
    "ax2.plot(np.arange(train_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]), df_val['EURUSDV1Y Curncy Trade Open'], label='Validation data')\n",
    "\n",
    "ax2.plot(np.arange(train_data.shape[0]+val_data.shape[0], \n",
    "                   train_data.shape[0]+val_data.shape[0]+test_data.shape[0]), df_test['EURUSDV1Y Curncy Trade Open'], label='Test data')\n",
    "ax2.set_xlabel('Dates')\n",
    "ax2.set_ylabel('Normalized Volatility Changes')\n",
    "ax2.set_title(\"Volatility\", fontsize=18)\n",
    "ax2.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-9JDha_6l3L"
   },
   "source": [
    "## Create chunks of training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ib8wOc-_5llL",
    "outputId": "60209809-af34-43a2-f22c-c42c7c538769"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train, y_train = [], []\n",
    "for i in range(seq_len, len(train_data)):\n",
    "  X_train.append(train_data[i-seq_len:i]) # Chunks of training data with a length of 128 df-rows\n",
    "  y_train.append(train_data[:, 3][i]) #Value of 4th column (Close Price) of df-row 128+1\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Validation data\n",
    "X_val, y_val = [], []\n",
    "for i in range(seq_len, len(val_data)):\n",
    "    X_val.append(val_data[i-seq_len:i])\n",
    "    y_val.append(val_data[:, 3][i])\n",
    "X_val, y_val = np.array(X_val), np.array(y_val)\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "# Test data\n",
    "X_test, y_test = [], []\n",
    "for i in range(seq_len, len(test_data)):\n",
    "    X_test.append(test_data[i-seq_len:i])\n",
    "    y_test.append(test_data[:, 3][i])    \n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "print('Training set shape', X_train.shape, y_train.shape)\n",
    "print('Validation set shape', X_val.shape, y_val.shape)\n",
    "print('Testing set shape' ,X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WhTPe6I6sDu"
   },
   "source": [
    "## TimeVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUawOlTD5ljR"
   },
   "outputs": [],
   "source": [
    "class Time2Vector(Layer):\n",
    "  def __init__(self, seq_len, **kwargs):\n",
    "    super(Time2Vector, self).__init__()\n",
    "    self.seq_len = seq_len\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    '''Initialize weights and biases with shape (batch, seq_len)'''\n",
    "    self.weights_linear = self.add_weight(name='weight_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.bias_linear = self.add_weight(name='bias_linear',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "    \n",
    "    self.weights_periodic = self.add_weight(name='weight_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "    self.bias_periodic = self.add_weight(name='bias_periodic',\n",
    "                                shape=(int(self.seq_len),),\n",
    "                                initializer='uniform',\n",
    "                                trainable=True)\n",
    "\n",
    "  def call(self, x):\n",
    "    '''Calculate linear and periodic time features'''\n",
    "    x = tf.math.reduce_mean(x[:,:,:4], axis=-1) \n",
    "    time_linear = self.weights_linear * x + self.bias_linear # Linear time feature\n",
    "    time_linear = tf.expand_dims(time_linear, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    \n",
    "    time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)\n",
    "    time_periodic = tf.expand_dims(time_periodic, axis=-1) # Add dimension (batch, seq_len, 1)\n",
    "    return tf.concat([time_linear, time_periodic], axis=-1) # shape = (batch, seq_len, 2)\n",
    "   \n",
    "  def get_config(self): # Needed for saving and loading model with custom layer\n",
    "    config = super().get_config().copy()\n",
    "    config.update({'seq_len': self.seq_len})\n",
    "    return config\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJZOW8d56wyJ"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Veb1wu_5lhE"
   },
   "outputs": [],
   "source": [
    "class SingleAttention(Layer):\n",
    "  def __init__(self, d_k, d_v):\n",
    "    super(SingleAttention, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.query = Dense(self.d_k, \n",
    "                       input_shape=input_shape, \n",
    "                       kernel_initializer='glorot_uniform', \n",
    "                       bias_initializer='glorot_uniform')\n",
    "    \n",
    "    self.key = Dense(self.d_k, \n",
    "                     input_shape=input_shape, \n",
    "                     kernel_initializer='glorot_uniform', \n",
    "                     bias_initializer='glorot_uniform')\n",
    "    \n",
    "    self.value = Dense(self.d_v, \n",
    "                       input_shape=input_shape, \n",
    "                       kernel_initializer='glorot_uniform', \n",
    "                       bias_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "    q = self.query(inputs[0])\n",
    "    k = self.key(inputs[1])\n",
    "\n",
    "    attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "    attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.d_k), attn_weights)\n",
    "    attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "    \n",
    "    v = self.value(inputs[2])\n",
    "    attn_out = tf.matmul(attn_weights, v)\n",
    "    return attn_out    \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class MultiAttention(Layer):\n",
    "  def __init__(self, d_k, d_v, n_heads):\n",
    "    super(MultiAttention, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "    self.n_heads = n_heads\n",
    "    self.attn_heads = list()\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    for n in range(self.n_heads):\n",
    "      self.attn_heads.append(SingleAttention(self.d_k, self.d_v))  \n",
    "    \n",
    "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1]=7 \n",
    "    self.linear = Dense(input_shape[0][-1], \n",
    "                        input_shape=input_shape, \n",
    "                        kernel_initializer='glorot_uniform', \n",
    "                        bias_initializer='glorot_uniform')\n",
    "\n",
    "  def call(self, inputs):\n",
    "    attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "    concat_attn = tf.concat(attn, axis=-1)\n",
    "    multi_linear = self.linear(concat_attn)\n",
    "    return multi_linear   \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "class TransformerEncoder(Layer):\n",
    "  def __init__(self, d_k, d_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "    super(TransformerEncoder, self).__init__()\n",
    "    self.d_k = d_k\n",
    "    self.d_v = d_v\n",
    "    self.n_heads = n_heads\n",
    "    self.ff_dim = ff_dim\n",
    "    self.attn_heads = list()\n",
    "    self.dropout_rate = dropout\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.attn_multi = MultiAttention(self.d_k, self.d_v, self.n_heads)\n",
    "    self.attn_dropout = Dropout(self.dropout_rate)\n",
    "    self.attn_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "    self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "    # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \n",
    "    self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
    "    self.ff_dropout = Dropout(self.dropout_rate)\n",
    "    self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
    "  \n",
    "  def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "    attn_layer = self.attn_multi(inputs)\n",
    "    attn_layer = self.attn_dropout(attn_layer)\n",
    "    attn_layer = self.attn_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "    ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "    ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "    ff_layer = self.ff_dropout(ff_layer)\n",
    "    ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "    return ff_layer \n",
    "\n",
    "  def get_config(self): # Needed for saving and loading model with custom layer\n",
    "    config = super().get_config().copy()\n",
    "    config.update({'d_k': self.d_k,\n",
    "                   'd_v': self.d_v,\n",
    "                   'n_heads': self.n_heads,\n",
    "                   'ff_dim': self.ff_dim,\n",
    "                   'attn_heads': self.attn_heads,\n",
    "                   'dropout_rate': self.dropout_rate})\n",
    "    return config          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OtBanXmQB4jF"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n1z9GgwV5lZe",
    "outputId": "3a97e918-00c4-4aaf-c0d6-1fd821ce868c"
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "  '''Initialize time and transformer layers'''\n",
    "  time_embedding = Time2Vector(seq_len)\n",
    "  attn_layer1 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "  attn_layer2 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "  attn_layer3 = TransformerEncoder(d_k, d_v, n_heads, ff_dim)\n",
    "\n",
    "  '''Construct model'''\n",
    "  in_seq = Input(shape=(seq_len, input_shape))\n",
    "  x = time_embedding(in_seq)\n",
    "  x = Concatenate(axis=-1)([in_seq, x])\n",
    "#   x = Concatenate(axis=-1)([Dense(64)(in_seq), x])\n",
    "  x = attn_layer1((x, x, x))\n",
    "  x = attn_layer2((x, x, x))\n",
    "  x = attn_layer3((x, x, x))\n",
    "  x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "  x = Dropout(0.1)(x)\n",
    "  x = Dense(64, activation='relu')(x)\n",
    "  x = Dropout(0.1)(x)\n",
    "  out = Dense(1, activation='linear')(x)\n",
    "\n",
    "  model = Model(inputs=in_seq, outputs=out)\n",
    "  opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "  model.compile(loss='mse', optimizer=opt, metrics=['mae', 'mape'])\n",
    "  return model\n",
    "\n",
    "\n",
    "model = create_model(df.shape[1])\n",
    "model.summary()\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint('content/Transformer+TimeEmbedding{epoch}.hdf5', \n",
    "                                              monitor='val_loss', \n",
    "                                              save_best_only=True, verbose=1)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=8,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "\n",
    "if True: \n",
    "    history = model.fit(X_train, y_train,\n",
    "                        batch_size=batch_size, \n",
    "                        epochs=3, \n",
    "                        callbacks=[callback],\n",
    "                        validation_data=(X_val, y_val))  \n",
    "    with open('content/history.pkl', 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "# else    \n",
    "#    model.save(.h5)\n",
    "#    model.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_last = sorted([i for i in os.listdir('content') if 'hdf5' in i and 'Transformer+TimeEmbedding' in i])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n1z9GgwV5lZe",
    "outputId": "3a97e918-00c4-4aaf-c0d6-1fd821ce868c"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\n",
    "    os.path.join('content', model_last),\n",
    "    custom_objects={\n",
    "        'Time2Vector': Time2Vector,\n",
    "        'SingleAttention': SingleAttention,\n",
    "        'MultiAttention': MultiAttention,\n",
    "        'TransformerEncoder': TransformerEncoder\n",
    "    }\n",
    ")\n",
    "with open('content/history.pkl', 'rb') as f:\n",
    "    history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n1z9GgwV5lZe",
    "outputId": "3a97e918-00c4-4aaf-c0d6-1fd821ce868c"
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "'''Calculate predictions and metrics'''\n",
    "\n",
    "#Calculate predication for training, validation and test data\n",
    "train_pred = model.predict(X_train)\n",
    "val_pred = model.predict(X_val)\n",
    "test_pred = model.predict(X_test)\n",
    "\n",
    "#Print evaluation metrics for all datasets\n",
    "train_eval = model.evaluate(X_train, y_train, verbose=0)\n",
    "val_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "test_eval = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(' ')\n",
    "print('Evaluation metrics')\n",
    "print('Training Data - Loss: {:.4f}, MAE: {:.4f}, MAPE: {:.4f}'.format(train_eval[0], train_eval[1], train_eval[2]))\n",
    "print('Validation Data - Loss: {:.4f}, MAE: {:.4f}, MAPE: {:.4f}'.format(val_eval[0], val_eval[1], val_eval[2]))\n",
    "print('Test Data - Loss: {:.4f}, MAE: {:.4f}, MAPE: {:.4f}'.format(test_eval[0], test_eval[1], test_eval[2]))\n",
    "\n",
    "###############################################################################\n",
    "'''Display results'''\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Transformer + TimeEmbedding Model\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot training data results\n",
    "ax11 = fig.add_subplot(311)\n",
    "ax11.plot(train_data[:, 3], label='EURUSD Closing Returns')\n",
    "ax11.plot(np.arange(seq_len, train_pred.shape[0]+seq_len), train_pred, linewidth=3, label='Predicted EURUSD Closing Returns')\n",
    "ax11.set_title(\"Training Data\", fontsize=18)\n",
    "ax11.set_xlabel('Dates')\n",
    "ax11.set_ylabel('EURUSD Closing Returns')\n",
    "ax11.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot validation data results\n",
    "ax21 = fig.add_subplot(312)\n",
    "ax21.plot(val_data[:, 3], label='EURUSD Closing Returns')\n",
    "ax21.plot(np.arange(seq_len, val_pred.shape[0]+seq_len), val_pred, linewidth=3, label='Predicted EURUSD Closing Returns')\n",
    "ax21.set_title(\"Validation Data\", fontsize=18)\n",
    "ax21.set_xlabel('Dates')\n",
    "ax21.set_ylabel('EURUSD Closing Returns')\n",
    "ax21.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot test data results\n",
    "ax31 = fig.add_subplot(313)\n",
    "ax31.plot(test_data[:, 3], label='EURUSD Closing Returns')\n",
    "ax31.plot(np.arange(seq_len, test_pred.shape[0]+seq_len), test_pred, linewidth=3, label='Predicted EURUSD Closing Returns')\n",
    "ax31.set_title(\"Test Data\", fontsize=18)\n",
    "ax31.set_xlabel('Dates')\n",
    "ax31.set_ylabel('EURUSD Closing Returns')\n",
    "ax31.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QiCB_z-iCMMr"
   },
   "source": [
    "## Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "maSSTkJPCOE8",
    "outputId": "5a802a5b-bfc7-47c0-987a-8fca1ab84226"
   },
   "outputs": [],
   "source": [
    "'''Display model metrics'''\n",
    "\n",
    "fig = plt.figure(figsize=(15,20))\n",
    "st = fig.suptitle(\"Transformer + TimeEmbedding Model Metrics\", fontsize=22)\n",
    "st.set_y(0.92)\n",
    "\n",
    "#Plot model loss\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.plot(history['loss'], label='Training loss (MSE)')\n",
    "ax1.plot(history['val_loss'], label='Validation loss (MSE)')\n",
    "ax1.set_title(\"Model loss\", fontsize=18)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss (MSE)')\n",
    "ax1.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot MAE\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.plot(history['mae'], label='Training MAE')\n",
    "ax2.plot(history['val_mae'], label='Validation MAE')\n",
    "ax2.set_title(\"Model metric - Mean average error (MAE)\", fontsize=18)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Mean average error (MAE)')\n",
    "ax2.legend(loc=\"best\", fontsize=12)\n",
    "\n",
    "#Plot MAPE\n",
    "ax3 = fig.add_subplot(313)\n",
    "ax3.plot(history['mape'], label='Training MAPE')\n",
    "ax3.plot(history['val_mape'], label='Validation MAPE')\n",
    "ax3.set_title(\"Model metric - Mean average percentage error (MAPE)\", fontsize=18)\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Mean average percentage error (MAPE)')\n",
    "ax3.legend(loc=\"best\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5cvzV1ArCOwK"
   },
   "source": [
    "## Model architecture overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7b--iZiKCO5l",
    "outputId": "fa273886-666a-4ead-8d9e-e12083d4907b"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"EURUSD_Transformer+TimeEmbedding.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    expand_nested=True,\n",
    "    dpi=96,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "IBM_Transformer+TimeEmbedding.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fxpred3",
   "language": "python",
   "name": "fxpred3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
